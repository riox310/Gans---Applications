{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Cyaut6utnv"
      },
      "source": [
        "# Colab-DeblurGANv2\n",
        "\n",
        "Currently only one picture as input allowed.\n",
        "\n",
        "Original repo: [TAMU-VITA/DeblurGANv2](https://github.com/TAMU-VITA/DeblurGANv2)\n",
        "\n",
        "My coalb fork: [styler00dollar/Colab-DeblurGANv2](https://github.com/styler00dollar/Colab-DeblurGANv2)\n",
        "\n",
        "Simple tutoiral:\n",
        "Place ```input.png``` in ```Google Drive/Colab-DeblurGANv2``` and run these cells. You can create this folder with colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUTg2s-by8si"
      },
      "source": [
        "# check gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb3vhUOn5SzO",
        "cellView": "form"
      },
      "source": [
        "#@title Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9OIL78n5p2E"
      },
      "source": [
        "Either create input and output folders manually or with colab and place the files there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4FJ_R7d5W2a",
        "cellView": "form"
      },
      "source": [
        "#@title [Optional] Creating empty ```\"/content/drive/My Drive/Colab-DeblurGANv2/\"``` folder in Google Drive\n",
        "!mkdir \"/content/drive/My Drive/Colab-DeblurGANv2/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQbbcY7Ouzd_"
      },
      "source": [
        "# Deblur with InceptionResNet-v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G9sFBtrnmZz",
        "cellView": "form"
      },
      "source": [
        "#@title Installing and downloading model\n",
        "%cd /content/\n",
        "!git clone https://github.com/styler00dollar/Colab-DeblurGANv2\n",
        "!pip install fire\n",
        "!pip install pretrainedmodels\n",
        "!pip install gdown\n",
        "%cd /content/Colab-DeblurGANv2/models\n",
        "!gdown --id 1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW6au4DWuJkV"
      },
      "source": [
        "#@title Changing predict.py\n",
        "%%writefile /content/Colab-DeblurGANv2/predict.py\n",
        "import os\n",
        "from glob import glob\n",
        "from typing import Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from fire import Fire\n",
        "from tqdm import tqdm\n",
        "\n",
        "from aug import get_normalize\n",
        "from models.networks import get_generator\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, weights_path: str, model_name: str = ''):\n",
        "        with open('config/config.yaml') as cfg_file:\n",
        "            cfg = yaml.safe_load(cfg_file)\n",
        "        model = get_generator(model_name or cfg['model'])\n",
        "        model.load_state_dict(torch.load(weights_path)['model'])\n",
        "        self.model = model.cuda()\n",
        "        self.model.train(True)\n",
        "        # GAN inference should be in train mode to use actual stats in norm layers,\n",
        "        # it's not a bug\n",
        "        self.normalize_fn = get_normalize()\n",
        "\n",
        "    @staticmethod\n",
        "    def _array_to_batch(x):\n",
        "        x = np.transpose(x, (2, 0, 1))\n",
        "        x = np.expand_dims(x, 0)\n",
        "        return torch.from_numpy(x)\n",
        "\n",
        "    def _preprocess(self, x: np.ndarray, mask: Optional[np.ndarray]):\n",
        "        x, _ = self.normalize_fn(x, x)\n",
        "        if mask is None:\n",
        "            mask = np.ones_like(x, dtype=np.float32)\n",
        "        else:\n",
        "            mask = np.round(mask.astype('float32') / 255)\n",
        "\n",
        "        h, w, _ = x.shape\n",
        "        block_size = 32\n",
        "        min_height = (h // block_size + 1) * block_size\n",
        "        min_width = (w // block_size + 1) * block_size\n",
        "\n",
        "        pad_params = {'mode': 'constant',\n",
        "                      'constant_values': 0,\n",
        "                      'pad_width': ((0, min_height - h), (0, min_width - w), (0, 0))\n",
        "                      }\n",
        "        x = np.pad(x, **pad_params)\n",
        "        mask = np.pad(mask, **pad_params)\n",
        "\n",
        "        return map(self._array_to_batch, (x, mask)), h, w\n",
        "\n",
        "    @staticmethod\n",
        "    def _postprocess(x: torch.Tensor) -> np.ndarray:\n",
        "        x, = x\n",
        "        x = x.detach().cpu().float().numpy()\n",
        "        x = (np.transpose(x, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
        "        return x.astype('uint8')\n",
        "\n",
        "    def __call__(self, img: np.ndarray, mask: Optional[np.ndarray], ignore_mask=True) -> np.ndarray:\n",
        "        (img, mask), h, w = self._preprocess(img, mask)\n",
        "        with torch.no_grad():\n",
        "            inputs = [img.cuda()]\n",
        "            if not ignore_mask:\n",
        "                inputs += [mask]\n",
        "            pred = self.model(*inputs)\n",
        "        return self._postprocess(pred)[:h, :w, :]\n",
        "\n",
        "\n",
        "def process_video(pairs, predictor, output_dir):\n",
        "    for video_filepath, mask in tqdm(pairs):\n",
        "        video_filename = os.path.basename(video_filepath)\n",
        "        output_filepath = os.path.join(output_dir, os.path.splitext(video_filename)[0]+'_deblur.mp4')\n",
        "        video_in = cv2.VideoCapture(video_filepath)\n",
        "        fps = video_in.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(video_in.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(video_in.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frame_num = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        video_out = cv2.VideoWriter(output_filepath, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n",
        "        tqdm.write(f'process {video_filepath} to {output_filepath}, {fps}fps, resolution: {width}x{height}')\n",
        "        for frame_num in tqdm(range(total_frame_num), desc=video_filename):\n",
        "            res, img = video_in.read()\n",
        "            if not res:\n",
        "                break\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            pred = predictor(img, mask)\n",
        "            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n",
        "            video_out.write(pred)\n",
        "\n",
        "\n",
        "def main(img_pattern: str,\n",
        "         mask_pattern: Optional[str] = None,\n",
        "         weights_path='/content/Colab-DeblurGANv2/models/fpn_inception.h5',\n",
        "         out_dir='submit/',\n",
        "         side_by_side: bool = False,\n",
        "         video: bool = False):\n",
        "    def sorted_glob(pattern):\n",
        "        return sorted(glob(pattern))\n",
        "\n",
        "    imgs = sorted_glob(img_pattern)\n",
        "    masks = sorted_glob(mask_pattern) if mask_pattern is not None else [None for _ in imgs]\n",
        "    pairs = zip(imgs, masks)\n",
        "    names = sorted([os.path.basename(x) for x in glob(img_pattern)])\n",
        "    predictor = Predictor(weights_path=weights_path)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    if not video:\n",
        "        for name, pair in tqdm(zip(names, pairs), total=len(names)):\n",
        "            f_img, f_mask = pair\n",
        "            img, mask = map(cv2.imread, (f_img, f_mask))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            pred = predictor(img, mask)\n",
        "            if side_by_side:\n",
        "                pred = np.hstack((img, pred))\n",
        "            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n",
        "            cv2.imwrite(os.path.join(out_dir, name),\n",
        "                        pred)\n",
        "    else:\n",
        "        process_video(pairs, predictor, out_dir)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Fire(main)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lImGMorGKGTd",
        "cellView": "form"
      },
      "source": [
        "#@title Downloading model from my Google Drive (Very fast download)\n",
        "!mkdir /root/\n",
        "!mkdir /root/.cache/\n",
        "!mkdir /root/.cache/torch/\n",
        "!mkdir /root/.cache/torch/checkpoints/\n",
        "%cd /root/.cache/torch/checkpoints/\n",
        "!gdown --id 1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUQxom6W4YDw",
        "cellView": "form"
      },
      "source": [
        "#@title ```[OPTIONAL / ONLY RUN THIS IF YOU HAVE PROBLEMS WITH THE PREVIOUS CELL]``` Testrun to download model file with pretrainedmodels (Download takes around 10 minutes)\n",
        "%cd /content/\n",
        "!wget --no-check-certificate https://raw.githubusercontent.com/xinntao/ESRGAN/master/LR/baboon.png\n",
        "%cd /content/Colab-DeblurGANv2\n",
        "!python predict.py /content/baboon.png\n",
        "%cd /content/\n",
        "!sudo rm /content/baboon.png\n",
        "!sudo rm /content/Colab-DeblurGANv2/submit/baboon.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kImTgk3pncs"
      },
      "source": [
        "#@title Run deblur and copy result go Google Drive\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/000in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/000in.png \"/content/drive/My Drive/Colab-DeblurGANv2/000out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/001in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/001in.png \"/content/drive/My Drive/Colab-DeblurGANv2/001out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/002in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/002in.png \"/content/drive/My Drive/Colab-DeblurGANv2/002out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/003in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/003in.png \"/content/drive/My Drive/Colab-DeblurGANv2/003out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/004in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/004in.png \"/content/drive/My Drive/Colab-DeblurGANv2/004out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/005in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/005in.png \"/content/drive/My Drive/Colab-DeblurGANv2/005out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/006in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/006in.png \"/content/drive/My Drive/Colab-DeblurGANv2/006out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/007in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/007in.png \"/content/drive/My Drive/Colab-DeblurGANv2/007out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/008in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/008in.png \"/content/drive/My Drive/Colab-DeblurGANv2/008out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/009in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/009in.png \"/content/drive/My Drive/Colab-DeblurGANv2/009out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/010in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/010in.png \"/content/drive/My Drive/Colab-DeblurGANv2/010out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/011in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/011in.png \"/content/drive/My Drive/Colab-DeblurGANv2/011out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/012in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/012in.png \"/content/drive/My Drive/Colab-DeblurGANv2/012out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/013in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/013in.png \"/content/drive/My Drive/Colab-DeblurGANv2/013out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/014in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/014in.png \"/content/drive/My Drive/Colab-DeblurGANv2/014out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/015in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/015in.png \"/content/drive/My Drive/Colab-DeblurGANv2/015out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/016in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/016in.png \"/content/drive/My Drive/Colab-DeblurGANv2/016out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/017in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/017in.png \"/content/drive/My Drive/Colab-DeblurGANv2/017out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/018in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/018in.png \"/content/drive/My Drive/Colab-DeblurGANv2/018out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/019in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/019in.png \"/content/drive/My Drive/Colab-DeblurGANv2/019out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/020in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/020in.png \"/content/drive/My Drive/Colab-DeblurGANv2/020out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/021in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/021in.png \"/content/drive/My Drive/Colab-DeblurGANv2/021out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/022in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/022in.png \"/content/drive/My Drive/Colab-DeblurGANv2/022out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/023in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/023in.png \"/content/drive/My Drive/Colab-DeblurGANv2/023out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/024in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/024in.png \"/content/drive/My Drive/Colab-DeblurGANv2/024out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/025in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/025in.png \"/content/drive/My Drive/Colab-DeblurGANv2/025out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/026in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/026in.png \"/content/drive/My Drive/Colab-DeblurGANv2/026out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/027in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/027in.png \"/content/drive/My Drive/Colab-DeblurGANv2/027out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/028in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/028in.png \"/content/drive/My Drive/Colab-DeblurGANv2/028out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/029in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/029in.png \"/content/drive/My Drive/Colab-DeblurGANv2/029out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/030in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/030in.png \"/content/drive/My Drive/Colab-DeblurGANv2/030out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/031in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/031in.png \"/content/drive/My Drive/Colab-DeblurGANv2/031out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/032in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/032in.png \"/content/drive/My Drive/Colab-DeblurGANv2/032out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/033in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/033in.png \"/content/drive/My Drive/Colab-DeblurGANv2/033out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/034in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/034in.png \"/content/drive/My Drive/Colab-DeblurGANv2/034out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/035in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/035in.png \"/content/drive/My Drive/Colab-DeblurGANv2/035out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/036in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/036in.png \"/content/drive/My Drive/Colab-DeblurGANv2/036out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/037in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/037in.png \"/content/drive/My Drive/Colab-DeblurGANv2/037out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/038in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/038in.png \"/content/drive/My Drive/Colab-DeblurGANv2/038out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/039in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/039in.png \"/content/drive/My Drive/Colab-DeblurGANv2/039out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/040in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/040in.png \"/content/drive/My Drive/Colab-DeblurGANv2/040out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/041in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/041in.png \"/content/drive/My Drive/Colab-DeblurGANv2/041out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/042in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/042in.png \"/content/drive/My Drive/Colab-DeblurGANv2/042out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/043in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/043in.png \"/content/drive/My Drive/Colab-DeblurGANv2/043out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/044in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/044in.png \"/content/drive/My Drive/Colab-DeblurGANv2/044out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/045in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/045in.png \"/content/drive/My Drive/Colab-DeblurGANv2/045out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/046in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/046in.png \"/content/drive/My Drive/Colab-DeblurGANv2/046out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/047in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/047in.png \"/content/drive/My Drive/Colab-DeblurGANv2/047out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/048in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/048in.png \"/content/drive/My Drive/Colab-DeblurGANv2/048out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/049in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/049in.png \"/content/drive/My Drive/Colab-DeblurGANv2/049out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/050in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/050in.png \"/content/drive/My Drive/Colab-DeblurGANv2/050out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/051in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/051in.png \"/content/drive/My Drive/Colab-DeblurGANv2/051out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/052in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/052in.png \"/content/drive/My Drive/Colab-DeblurGANv2/052out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/053in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/053in.png \"/content/drive/My Drive/Colab-DeblurGANv2/053out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/054in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/054in.png \"/content/drive/My Drive/Colab-DeblurGANv2/054out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/055in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/055in.png \"/content/drive/My Drive/Colab-DeblurGANv2/055out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/056in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/056in.png \"/content/drive/My Drive/Colab-DeblurGANv2/056out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/057in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/057in.png \"/content/drive/My Drive/Colab-DeblurGANv2/057out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/058in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/058in.png \"/content/drive/My Drive/Colab-DeblurGANv2/058out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/059in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/059in.png \"/content/drive/My Drive/Colab-DeblurGANv2/059out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/060in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/060in.png \"/content/drive/My Drive/Colab-DeblurGANv2/060out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/061in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/061in.png \"/content/drive/My Drive/Colab-DeblurGANv2/061out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/062in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/062in.png \"/content/drive/My Drive/Colab-DeblurGANv2/062out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/063in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/063in.png \"/content/drive/My Drive/Colab-DeblurGANv2/063out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/064in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/064in.png \"/content/drive/My Drive/Colab-DeblurGANv2/064out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/065in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/065in.png \"/content/drive/My Drive/Colab-DeblurGANv2/065out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/066in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/066in.png \"/content/drive/My Drive/Colab-DeblurGANv2/066out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/067in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/067in.png \"/content/drive/My Drive/Colab-DeblurGANv2/067out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/068in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/068in.png \"/content/drive/My Drive/Colab-DeblurGANv2/068out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/069in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/069in.png \"/content/drive/My Drive/Colab-DeblurGANv2/069out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/070in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/070in.png \"/content/drive/My Drive/Colab-DeblurGANv2/070out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/071in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/071in.png \"/content/drive/My Drive/Colab-DeblurGANv2/071out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/072in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/072in.png \"/content/drive/My Drive/Colab-DeblurGANv2/072out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/073in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/073in.png \"/content/drive/My Drive/Colab-DeblurGANv2/073out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/074in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/074in.png \"/content/drive/My Drive/Colab-DeblurGANv2/074out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/075in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/075in.png \"/content/drive/My Drive/Colab-DeblurGANv2/075out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/076in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/076in.png \"/content/drive/My Drive/Colab-DeblurGANv2/076out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/077in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/077in.png \"/content/drive/My Drive/Colab-DeblurGANv2/077out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/078in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/078in.png \"/content/drive/My Drive/Colab-DeblurGANv2/078out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/079in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/079in.png \"/content/drive/My Drive/Colab-DeblurGANv2/079out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/080in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/080in.png \"/content/drive/My Drive/Colab-DeblurGANv2/080out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/081in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/081in.png \"/content/drive/My Drive/Colab-DeblurGANv2/081out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/082in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/082in.png \"/content/drive/My Drive/Colab-DeblurGANv2/082out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/083in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/083in.png \"/content/drive/My Drive/Colab-DeblurGANv2/083out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/084in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/084in.png \"/content/drive/My Drive/Colab-DeblurGANv2/084out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/085in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/085in.png \"/content/drive/My Drive/Colab-DeblurGANv2/085out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/086in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/086in.png \"/content/drive/My Drive/Colab-DeblurGANv2/086out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/087in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/087in.png \"/content/drive/My Drive/Colab-DeblurGANv2/087out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/088in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/088in.png \"/content/drive/My Drive/Colab-DeblurGANv2/088out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/089in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/089in.png \"/content/drive/My Drive/Colab-DeblurGANv2/089out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/090in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/090in.png \"/content/drive/My Drive/Colab-DeblurGANv2/090out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/091in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/091in.png \"/content/drive/My Drive/Colab-DeblurGANv2/091out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/092in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/092in.png \"/content/drive/My Drive/Colab-DeblurGANv2/092out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/093in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/093in.png \"/content/drive/My Drive/Colab-DeblurGANv2/093out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/094in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/094in.png \"/content/drive/My Drive/Colab-DeblurGANv2/094out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/095in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/095in.png \"/content/drive/My Drive/Colab-DeblurGANv2/095out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/096in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/096in.png \"/content/drive/My Drive/Colab-DeblurGANv2/096out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/097in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/097in.png \"/content/drive/My Drive/Colab-DeblurGANv2/097out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/098in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/098in.png \"/content/drive/My Drive/Colab-DeblurGANv2/098out.png\"\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/099in.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/099in.png \"/content/drive/My Drive/Colab-DeblurGANv2/099out.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qucha-Su4J7"
      },
      "source": [
        "# Deblur with MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZmeIqZ8u8YL",
        "cellView": "form"
      },
      "source": [
        "#@title Installing and downloading models\n",
        "%cd /content/\n",
        "!git clone https://github.com/styler00dollar/Colab-DeblurGANv2\n",
        "!pip install fire\n",
        "!pip install pretrainedmodels\n",
        "!pip install gdown\n",
        "%cd /content/Colab-DeblurGANv2/models\n",
        "!gdown --id 1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR\n",
        "!wget --no-check-certificate http://sceneparsing.csail.mit.edu/model/pretrained_resnet/mobilenet_v2.pth.tar\n",
        "!gdown --id 1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-xu__FIp6Jz",
        "cellView": "form"
      },
      "source": [
        "#@title Changing config.yaml\n",
        "%%writefile /content/Colab-DeblurGANv2/config/config.yaml\n",
        "---\n",
        "project: deblur_gan\n",
        "experiment_desc: fpn\n",
        "\n",
        "train:\n",
        "  files_a: &FILES_A /datasets/my_dataset/**/*.jpg\n",
        "  files_b: *FILES_A\n",
        "  size: &SIZE 256\n",
        "  crop: random\n",
        "  preload: &PRELOAD false\n",
        "  preload_size: &PRELOAD_SIZE 0\n",
        "  bounds: [0, .9]\n",
        "  scope: geometric\n",
        "  corrupt: &CORRUPT\n",
        "    - name: cutout\n",
        "      prob: 0.5\n",
        "      num_holes: 3\n",
        "      max_h_size: 25\n",
        "      max_w_size: 25\n",
        "    - name: jpeg\n",
        "      quality_lower: 70\n",
        "      quality_upper: 90\n",
        "    - name: motion_blur\n",
        "    - name: median_blur\n",
        "    - name: gamma\n",
        "    - name: rgb_shift\n",
        "    - name: hsv_shift\n",
        "    - name: sharpen\n",
        "\n",
        "val:\n",
        "  files_a: *FILES_A\n",
        "  files_b: *FILES_A\n",
        "  size: *SIZE\n",
        "  scope: geometric\n",
        "  crop: center\n",
        "  preload: *PRELOAD\n",
        "  preload_size: *PRELOAD_SIZE\n",
        "  bounds: [.9, 1]\n",
        "  corrupt: *CORRUPT\n",
        "\n",
        "phase: train\n",
        "warmup_num: 3\n",
        "model:\n",
        "  g_name: fpn_mobilenet\n",
        "  blocks: 9\n",
        "  d_name: double_gan # may be no_gan, patch_gan, double_gan, multi_scale\n",
        "  d_layers: 3\n",
        "  content_loss: perceptual\n",
        "  adv_lambda: 0.001\n",
        "  disc_loss: wgan-gp\n",
        "  learn_residual: True\n",
        "  norm_layer: instance\n",
        "  dropout: True\n",
        "\n",
        "num_epochs: 200\n",
        "train_batches_per_epoch: 1000\n",
        "val_batches_per_epoch: 100\n",
        "batch_size: 1\n",
        "image_size: [256, 256]\n",
        "\n",
        "optimizer:\n",
        "  name: adam\n",
        "  lr: 0.0001\n",
        "scheduler:\n",
        "  name: linear\n",
        "  start_epoch: 50\n",
        "  min_lr: 0.0000001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOarMZ1Kvjgv",
        "cellView": "form"
      },
      "source": [
        "#@title Changing predict.py\n",
        "%%writefile /content/Colab-DeblurGANv2/predict.py\n",
        "import os\n",
        "from glob import glob\n",
        "from typing import Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from fire import Fire\n",
        "from tqdm import tqdm\n",
        "\n",
        "from aug import get_normalize\n",
        "from models.networks import get_generator\n",
        "\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, weights_path: str, model_name: str = ''):\n",
        "        with open('config/config.yaml') as cfg:\n",
        "            config = yaml.load(cfg)\n",
        "        model = get_generator(model_name or config['model'])\n",
        "        model.load_state_dict(torch.load(weights_path)['model'])\n",
        "        self.model = model.cuda()\n",
        "        self.model.train(True)\n",
        "        # GAN inference should be in train mode to use actual stats in norm layers,\n",
        "        # it's not a bug\n",
        "        self.normalize_fn = get_normalize()\n",
        "\n",
        "    @staticmethod\n",
        "    def _array_to_batch(x):\n",
        "        x = np.transpose(x, (2, 0, 1))\n",
        "        x = np.expand_dims(x, 0)\n",
        "        return torch.from_numpy(x)\n",
        "\n",
        "    def _preprocess(self, x: np.ndarray, mask: Optional[np.ndarray]):\n",
        "        x, _ = self.normalize_fn(x, x)\n",
        "        if mask is None:\n",
        "            mask = np.ones_like(x, dtype=np.float32)\n",
        "        else:\n",
        "            mask = np.round(mask.astype('float32') / 255)\n",
        "\n",
        "        h, w, _ = x.shape\n",
        "        block_size = 32\n",
        "        min_height = (h // block_size + 1) * block_size\n",
        "        min_width = (w // block_size + 1) * block_size\n",
        "\n",
        "        pad_params = {'mode': 'constant',\n",
        "                      'constant_values': 0,\n",
        "                      'pad_width': ((0, min_height - h), (0, min_width - w), (0, 0))\n",
        "                      }\n",
        "        x = np.pad(x, **pad_params)\n",
        "        mask = np.pad(mask, **pad_params)\n",
        "\n",
        "        return map(self._array_to_batch, (x, mask)), h, w\n",
        "\n",
        "    @staticmethod\n",
        "    def _postprocess(x: torch.Tensor) -> np.ndarray:\n",
        "        x, = x\n",
        "        x = x.detach().cpu().float().numpy()\n",
        "        x = (np.transpose(x, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
        "        return x.astype('uint8')\n",
        "\n",
        "    def __call__(self, img: np.ndarray, mask: Optional[np.ndarray], ignore_mask=True) -> np.ndarray:\n",
        "        (img, mask), h, w = self._preprocess(img, mask)\n",
        "        with torch.no_grad():\n",
        "            inputs = [img.cuda()]\n",
        "            if not ignore_mask:\n",
        "                inputs += [mask]\n",
        "            pred = self.model(*inputs)\n",
        "        return self._postprocess(pred)[:h, :w, :]\n",
        "\n",
        "def process_video(pairs, predictor, output_dir):\n",
        "    for video_filepath, mask in tqdm(pairs):\n",
        "        video_filename = os.path.basename(video_filepath)\n",
        "        output_filepath = os.path.join(output_dir, os.path.splitext(video_filename)[0]+'_deblur.mp4')\n",
        "        video_in = cv2.VideoCapture(video_filepath)\n",
        "        fps = video_in.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(video_in.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(video_in.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frame_num = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        video_out = cv2.VideoWriter(output_filepath, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n",
        "        tqdm.write(f'process {video_filepath} to {output_filepath}, {fps}fps, resolution: {width}x{height}')\n",
        "        for frame_num in tqdm(range(total_frame_num), desc=video_filename):\n",
        "            res, img = video_in.read()\n",
        "            if not res:\n",
        "                break\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            pred = predictor(img, mask)\n",
        "            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n",
        "            video_out.write(pred)\n",
        "\n",
        "def main(img_pattern: str,\n",
        "         mask_pattern: Optional[str] = None,\n",
        "         weights_path='/content/Colab-DeblurGANv2/models/fpn_mobilenet.h5',\n",
        "         out_dir='submit/',\n",
        "         side_by_side: bool = False,\n",
        "         video: bool = False):\n",
        "    def sorted_glob(pattern):\n",
        "        return sorted(glob(pattern))\n",
        "\n",
        "    imgs = sorted_glob(img_pattern)\n",
        "    masks = sorted_glob(mask_pattern) if mask_pattern is not None else [None for _ in imgs]\n",
        "    pairs = zip(imgs, masks)\n",
        "    names = sorted([os.path.basename(x) for x in glob(img_pattern)])\n",
        "    predictor = Predictor(weights_path=weights_path)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    if not video:\n",
        "        for name, pair in tqdm(zip(names, pairs), total=len(names)):\n",
        "            f_img, f_mask = pair\n",
        "            img, mask = map(cv2.imread, (f_img, f_mask))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            pred = predictor(img, mask)\n",
        "            if side_by_side:\n",
        "                pred = np.hstack((img, pred))\n",
        "            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n",
        "            cv2.imwrite(os.path.join(out_dir, name),\n",
        "                        pred)\n",
        "    else:\n",
        "        process_video(pairs, predictor, out_dir)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Fire(main)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9tNNNpKxiNG",
        "cellView": "form"
      },
      "source": [
        "#@title Changing fpn_mobilenet.py\n",
        "%%writefile /content/Colab-DeblurGANv2/models/fpn_mobilenet.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from models.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "class FPNHead(nn.Module):\n",
        "    def __init__(self, num_in, num_mid, num_out):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block0 = nn.Conv2d(num_in, num_mid, kernel_size=3, padding=1, bias=False)\n",
        "        self.block1 = nn.Conv2d(num_mid, num_out, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.block0(x), inplace=True)\n",
        "        x = nn.functional.relu(self.block1(x), inplace=True)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FPNMobileNet(nn.Module):\n",
        "\n",
        "    def __init__(self, norm_layer, output_ch=3, num_filters=64, num_filters_fpn=128, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature Pyramid Network (FPN) with four feature maps of resolutions\n",
        "        # 1/4, 1/8, 1/16, 1/32 and `num_filters` filters for all feature maps.\n",
        "\n",
        "        self.fpn = FPN(num_filters=num_filters_fpn, norm_layer = norm_layer, pretrained=pretrained)\n",
        "\n",
        "        # The segmentation heads on top of the FPN\n",
        "\n",
        "        self.head1 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
        "        self.head2 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
        "        self.head3 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
        "        self.head4 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
        "\n",
        "        self.smooth = nn.Sequential(\n",
        "            nn.Conv2d(4 * num_filters, num_filters, kernel_size=3, padding=1),\n",
        "            norm_layer(num_filters),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.smooth2 = nn.Sequential(\n",
        "            nn.Conv2d(num_filters, num_filters // 2, kernel_size=3, padding=1),\n",
        "            norm_layer(num_filters // 2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.final = nn.Conv2d(num_filters // 2, output_ch, kernel_size=3, padding=1)\n",
        "\n",
        "    def unfreeze(self):\n",
        "        self.fpn.unfreeze()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        map0, map1, map2, map3, map4 = self.fpn(x)\n",
        "\n",
        "        map4 = nn.functional.upsample(self.head4(map4), scale_factor=8, mode=\"nearest\")\n",
        "        map3 = nn.functional.upsample(self.head3(map3), scale_factor=4, mode=\"nearest\")\n",
        "        map2 = nn.functional.upsample(self.head2(map2), scale_factor=2, mode=\"nearest\")\n",
        "        map1 = nn.functional.upsample(self.head1(map1), scale_factor=1, mode=\"nearest\")\n",
        "\n",
        "        smoothed = self.smooth(torch.cat([map4, map3, map2, map1], dim=1))\n",
        "        smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n",
        "        smoothed = self.smooth2(smoothed + map0)\n",
        "        smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n",
        "\n",
        "        final = self.final(smoothed)\n",
        "        res = torch.tanh(final) + x\n",
        "\n",
        "        return torch.clamp(res, min=-1, max=1)\n",
        "\n",
        "\n",
        "class FPN(nn.Module):\n",
        "\n",
        "    def __init__(self, norm_layer, num_filters=128, pretrained=True):\n",
        "        \"\"\"Creates an `FPN` instance for feature extraction.\n",
        "        Args:\n",
        "          num_filters: the number of filters in each output pyramid level\n",
        "          pretrained: use ImageNet pre-trained backbone feature extractor\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        net = MobileNetV2(n_class=1000)\n",
        "\n",
        "        if pretrained:\n",
        "            #Load weights into the project directory\n",
        "            state_dict = torch.load('/content/Colab-DeblurGANv2/models/mobilenet_v2.pth.tar') # add map_location='cpu' if no gpu\n",
        "            net.load_state_dict(state_dict)\n",
        "        self.features = net.features\n",
        "\n",
        "        self.enc0 = nn.Sequential(*self.features[0:2])\n",
        "        self.enc1 = nn.Sequential(*self.features[2:4])\n",
        "        self.enc2 = nn.Sequential(*self.features[4:7])\n",
        "        self.enc3 = nn.Sequential(*self.features[7:11])\n",
        "        self.enc4 = nn.Sequential(*self.features[11:16])\n",
        "\n",
        "        self.td1 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n",
        "                                 norm_layer(num_filters),\n",
        "                                 nn.ReLU(inplace=True))\n",
        "        self.td2 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n",
        "                                 norm_layer(num_filters),\n",
        "                                 nn.ReLU(inplace=True))\n",
        "        self.td3 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n",
        "                                 norm_layer(num_filters),\n",
        "                                 nn.ReLU(inplace=True))\n",
        "\n",
        "        self.lateral4 = nn.Conv2d(160, num_filters, kernel_size=1, bias=False)\n",
        "        self.lateral3 = nn.Conv2d(64, num_filters, kernel_size=1, bias=False)\n",
        "        self.lateral2 = nn.Conv2d(32, num_filters, kernel_size=1, bias=False)\n",
        "        self.lateral1 = nn.Conv2d(24, num_filters, kernel_size=1, bias=False)\n",
        "        self.lateral0 = nn.Conv2d(16, num_filters // 2, kernel_size=1, bias=False)\n",
        "\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze(self):\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Bottom-up pathway, from ResNet\n",
        "        enc0 = self.enc0(x)\n",
        "\n",
        "        enc1 = self.enc1(enc0) # 256\n",
        "\n",
        "        enc2 = self.enc2(enc1) # 512\n",
        "\n",
        "        enc3 = self.enc3(enc2) # 1024\n",
        "\n",
        "        enc4 = self.enc4(enc3) # 2048\n",
        "\n",
        "        # Lateral connections\n",
        "\n",
        "        lateral4 = self.lateral4(enc4)\n",
        "        lateral3 = self.lateral3(enc3)\n",
        "        lateral2 = self.lateral2(enc2)\n",
        "        lateral1 = self.lateral1(enc1)\n",
        "        lateral0 = self.lateral0(enc0)\n",
        "\n",
        "        # Top-down pathway\n",
        "        map4 = lateral4\n",
        "        map3 = self.td1(lateral3 + nn.functional.upsample(map4, scale_factor=2, mode=\"nearest\"))\n",
        "        map2 = self.td2(lateral2 + nn.functional.upsample(map3, scale_factor=2, mode=\"nearest\"))\n",
        "        map1 = self.td3(lateral1 + nn.functional.upsample(map2, scale_factor=2, mode=\"nearest\"))\n",
        "        return lateral0, map1, map2, map3, map4\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSJm1AEVLu7a",
        "cellView": "form"
      },
      "source": [
        "#@title Downloading model from my Google Drive (Very fast download)\n",
        "!mkdir /root/\n",
        "!mkdir /root/.cache/\n",
        "!mkdir /root/.cache/torch/\n",
        "!mkdir /root/.cache/torch/checkpoints/\n",
        "%cd /root/.cache/torch/checkpoints/\n",
        "!gdown --id 1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZwavOot5Hbm",
        "cellView": "form"
      },
      "source": [
        "#@title ```[OPTIONAL / ONLY RUN THIS IF YOU HAVE PROBLEMS WITH THE PREVIOUS CELL]``` Testrun to download model file with pretrainedmodels (Download takes around 10 minutes)\n",
        "%cd /content/\n",
        "!wget --no-check-certificate https://raw.githubusercontent.com/xinntao/ESRGAN/master/LR/baboon.png\n",
        "%cd /content/Colab-DeblurGANv2\n",
        "!python predict.py /content/baboon.png\n",
        "\n",
        "#%cd /content/DeblurGANv2/models\n",
        "#!gdown --id 1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU\n",
        "%cd /root/.cache/torch/checkpoints\n",
        "!gdown --id 1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU\n",
        "%cd /content/Colab-DeblurGANv2/models\n",
        "!wget --no-check-certificate http://sceneparsing.csail.mit.edu/model/pretrained_resnet/mobilenet_v2.pth.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-rlVgQVv4lz",
        "cellView": "form"
      },
      "source": [
        "#@title Run deblur and copy result go Google Drive\n",
        "%cd /content/Colab-DeblurGANv2\n",
        "!python predict.py \"/content/drive/My Drive/Colab-DeblurGANv2/input.png\"\n",
        "!cp /content/Colab-DeblurGANv2/submit/input.png \"/content/drive/My Drive/Colab-DeblurGANv2/output.png\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}